<?xml version="1.0" encoding="UTF-8"?>
<!-- 多环境分级别异步文件日志输出配置 -->
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <springProperty scope="context" name="springAppName" source="spring.application.name"/>
    <!-- 日志级别 -->
    <property name="log.level" value="INFO"/>
    <!--日志文件的存储地址，勿在 LogBack 的配置中使用相对路径-->
    <property name="log.root" value="/output/logs"/>
    <!-- 日志名称 -->
    <property name="log.name" value="${springAppName:-}"/>
    <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n：是换行符-->
    <property name="log.colorPattern"
              value="%magenta(%d{'yyyy-MM-dd HH:mm:ss.SSS',GMT+8:00}) %highlight(%-5level) %boldCyan(${springAppName:-}) %yellow(%thread) %green(%logger) %msg%n"/>
    <property name="log.pattern" value="%d{'yyyy-MM-dd HH:mm:ss.SSS',GMT+8:00} %-5level ${springAppName:-} %thread %logger %msg%n"/>
    <!-- 活动文件的大小 -->
    <property name="max.file.size" value="500MB"/>
    <!-- 保留的归档文件的最大数量 -->
    <property name="max.history" value="30"/>
    <!-- 控制所有归档日志文件的总大小 -->
    <property name="total.size.cap" value="10GB"/>
    <!-- 异步缓冲队列的深度,该值会影响性能.默认值为256 -->
    <property name="queueSize" value="512"/>

    <!-- 控制台输出 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>${log.colorPattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- DEBUG日志 -->
    <appender name="DEBUG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.root}/${log.name}.debug.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>DEBUG</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${log.root}/${log.name}.debug.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>${max.file.size}</maxFileSize>
            <maxHistory>${max.history}</maxHistory>
            <totalSizeCap>${total.size.cap}</totalSizeCap>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>${log.pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- INFO日志 -->
    <appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.root}/${log.name}.info.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${log.root}/${log.name}.info.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>${max.file.size}</maxFileSize>
            <maxHistory>${max.history}</maxHistory>
            <totalSizeCap>${total.size.cap}</totalSizeCap>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>${log.pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- ERROR日志 -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.root}/${log.name}.error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${log.root}/${log.name}.error.%d{yyyy-MM-dd}.%i.log</fileNamePattern>
            <maxFileSize>${max.file.size}</maxFileSize>
            <maxHistory>${max.history}</maxHistory>
            <totalSizeCap>${total.size.cap}</totalSizeCap>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>${log.pattern}</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <appender name="ASYNC_LOG_DEBUG" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>${queueSize}</queueSize>
        <appender-ref ref="DEBUG_FILE"/>
    </appender>

    <appender name="ASYNC_LOG_INFO" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>${queueSize}</queueSize>
        <appender-ref ref="INFO_FILE"/>
    </appender>

    <appender name="ASYNC_LOG_ERROR" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>${queueSize}</queueSize>
        <appender-ref ref="ERROR_FILE"/>
    </appender>

    <!--    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">-->
    <!--        &lt;!&ndash;配置logStash 服务地址&ndash;&gt;-->
    <!--        <destination>127.0.0.1:9500</destination>-->
    <!--        &lt;!&ndash; 日志输出编码 &ndash;&gt;-->
    <!--        <encoder charset="UTF-8"-->
    <!--                 class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">-->
    <!--            <providers>-->
    <!--                <timestamp>-->
    <!--                    <timeZone>UTC</timeZone>-->
    <!--                </timestamp>-->
    <!--                <pattern>-->
    <!--                    <pattern>-->
    <!--                        {-->
    <!--                        "serviceName": "${springAppName:-}",-->
    <!--                        "logLevel": "%-5level",-->
    <!--                        "pid": "${PID:- }",-->
    <!--                        "thread": "%thread",-->
    <!--                        "class": "%logger{50}",-->
    <!--                        "msg": "%message"-->
    <!--                        }-->
    <!--                    </pattern>-->
    <!--                </pattern>-->
    <!--            </providers>-->
    <!--        </encoder>-->
    <!--    </appender>-->

    <!--mybatis log-->
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="java.sql.PreparedStatement" level="DEBUG"/>
    <logger name="druid.sql" level="INFO"/>
    <logger name="com.hdw" level="INFO"/>


    <springProfile name="dev">
        <root level="${log.level}">
            <appender-ref ref="STDOUT"/>
        </root>
    </springProfile>

    <springProfile name="prod">
        <root level="${log.level}">
            <appender-ref ref="STDOUT"/>
            <appender-ref ref="ASYNC_LOG_DEBUG"/>
            <appender-ref ref="ASYNC_LOG_INFO"/>
            <appender-ref ref="ASYNC_LOG_ERROR"/>
        </root>
    </springProfile>

    <springProfile name="test">
        <root level="${log.level}">
            <appender-ref ref="STDOUT"/>
            <appender-ref ref="ASYNC_LOG_DEBUG"/>
            <appender-ref ref="ASYNC_LOG_INFO"/>
            <appender-ref ref="ASYNC_LOG_ERROR"/>
        </root>
    </springProfile>

</configuration>